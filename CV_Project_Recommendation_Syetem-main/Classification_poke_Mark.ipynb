{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Classification and Pokemon API (90% Acc.)",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'pokemonclassification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F410745%2F786434%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240510%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240510T170826Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D035f868538bc87151d146fdfcae08d3bcb0a081b90f795919bcaca69f8afaf496176ff772c6cf7e14b949f16cf8bca73cbf8a5273a12a5885a1249001b301e79eaaeb5231238aa1b8a272e871793858aca1f77bb2b5815c4f400db2b641d22e5a7e2b9540421b396adf1b250df1aaa014ab3eb1b88c090a667b57430e8cbd76715d5848408b1a95317e06362039502ca352dc3c144f18ae8add4f8733b0f6eb5c3d1cb575d3c3f74bb2b4fb835c333ac0b865897d88d4ab5f9c0c28a1f7062fad3230e2ada8b6f4fcc696e002d997b7d6de062fd7d93e561df621f55af07622c6910148e6de66668755b8596ba0d83bc22b98108f14d492dc0b6fd93ec601c57'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "yCbfVVXOek1B"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import os\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "6mJvqx00ek1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Labels"
      ],
      "metadata": {
        "id": "s9a0BStoek1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"/kaggle/input/pokemonclassification/PokemonData\"\n",
        "labels = os.listdir(directory)\n",
        "nb = len(labels)\n",
        "print(labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "r5oLcD8pek1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nb)"
      ],
      "metadata": {
        "trusted": true,
        "id": "K_sxzRXpek1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "trusted": true,
        "id": "aXVbzabgek1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting images to Numpy arrays"
      ],
      "metadata": {
        "id": "yBRzLKAyek1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Changed their dimensions to 150 x 150\n",
        "* Normalized the pixel values"
      ],
      "metadata": {
        "id": "AWnF-iu8ek1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stored = {}\n",
        "def input_target_split(train_dir,labels):\n",
        "    dataset = []\n",
        "    count = 0\n",
        "    for label in labels:\n",
        "        folder = os.path.join(train_dir,label)\n",
        "        for image in os.listdir(folder):\n",
        "\n",
        "#             print(os.path.join(folder,image))\n",
        "            try:\n",
        "                img=load_img(os.path.join(folder,image), target_size=(150,150))\n",
        "                img=img_to_array(img)\n",
        "                img=img/255.0\n",
        "                dataset.append((img,count))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(f'\\rCompleted: {label}',end='')\n",
        "        stored[label] = count\n",
        "        count+=1\n",
        "    random.shuffle(dataset)\n",
        "    X, y = zip(*dataset)\n",
        "\n",
        "    return np.array(X),np.array(y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1iYxHe89ek1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = input_target_split(directory,labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ekf-LzMCek1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(stored)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_eB3ruJ1ek1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the images and their True labels"
      ],
      "metadata": {
        "id": "QVhgelL6ek1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (15 , 9))\n",
        "n = 0\n",
        "for i in range(15):\n",
        "    n+=1\n",
        "    plt.subplot(5 , 5, n)\n",
        "    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n",
        "    plt.imshow(X[i])\n",
        "    plt.title(f'Label: {labels[y[i]]}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "SvdeLlI5ek1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "vj_TxN47ek1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split and encoding of labels"
      ],
      "metadata": {
        "id": "VOATH4n2ek1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.22, random_state=42)\n",
        "print(np.unique(y_train,return_counts=True),np.unique(y_test,return_counts=True))"
      ],
      "metadata": {
        "trusted": true,
        "id": "1P4pOR2-ek1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                             vertical_flip=True,\n",
        "                             rotation_range=20,\n",
        "                             zoom_range=0.2,\n",
        "                             width_shift_range = 0.2,\n",
        "                             height_shift_range = 0.2,\n",
        "                             shear_range=0.1,\n",
        "                             fill_mode=\"nearest\")\n",
        "\n",
        "testgen = ImageDataGenerator()\n",
        "\n",
        "datagen.fit(X_train)\n",
        "testgen.fit(X_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "N2TXeGFhek1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.eye(nb)[y_train]\n",
        "y_test = np.eye(nb)[y_test]"
      ],
      "metadata": {
        "trusted": true,
        "id": "hccc9WqXek1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Freezing the DenseNet201 model upto layer 675"
      ],
      "metadata": {
        "id": "rPb8Nyzxek1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "img_size = 150\n",
        "base_model = DenseNet201(include_top = False,\n",
        "                         weights = 'imagenet',\n",
        "                         input_shape = (img_size,img_size,3))\n",
        "\n",
        "for layer in base_model.layers[:675]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model.layers[675:]:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "trusted": true,
        "id": "hxUTZZhcek1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward network for classifying 150 pokemon"
      ],
      "metadata": {
        "id": "E21wstb2ek1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(nb, activation=tf.nn.softmax))\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.001), loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "EMkzZxE_ek1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early stopping conditions in case model accuracy does not improve"
      ],
      "metadata": {
        "id": "KRZDnfmVek1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath= \"model_pokemon.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only=False)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',min_delta = 0, patience = 5, verbose = 1, restore_best_weights=True)\n",
        "\n",
        "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.2,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks_list = [\n",
        "        checkpoint,\n",
        "        early_stopping,\n",
        "        learning_rate_reduction\n",
        "    ]"
      ],
      "metadata": {
        "trusted": true,
        "id": "fIZq_9dFek1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=32),\n",
        "                                        validation_data=testgen.flow(X_test,y_test,batch_size=32),\n",
        "                                        epochs=50,\n",
        "                                        callbacks=callbacks_list)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ULbtI9bFek1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "pred = np.argmax(y_pred,axis=1)\n",
        "print(pred)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8ER6OmkCek1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JBA-2DVvek1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report"
      ],
      "metadata": {
        "id": "Ivegek9mek1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(ground,pred,target_names = labels))"
      ],
      "metadata": {
        "trusted": true,
        "id": "huEe5jCOek1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "trusted": true,
        "id": "ehODzcELek1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_pred,axis=1)\n",
        "y_pred"
      ],
      "metadata": {
        "trusted": true,
        "id": "HBNYRUKVek1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.argmax(y_test,axis=1)\n",
        "y_true"
      ],
      "metadata": {
        "trusted": true,
        "id": "H5ZX0T-yek1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the wrongly classified images"
      ],
      "metadata": {
        "id": "6kytvISgek1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15 , 9))\n",
        "n = 0\n",
        "for i in range(len(X_test)):\n",
        "    if y_pred[i] != y_true[i]:\n",
        "        n+=1\n",
        "        if n <= 25:\n",
        "            plt.subplot(5 , 5, n)\n",
        "            plt.subplots_adjust(hspace = 0.8 , wspace = 0.3)\n",
        "            plt.imshow(X_test[i])\n",
        "            plt.title(f'Actual: {labels[y_true[i]]}\\nPredicted: {labels[y_pred[i]]}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "RQBkXF5kek1U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
